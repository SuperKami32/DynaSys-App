{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9KfZAvZE/bnn+yjCSPHLS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SuperKami32/DynaSys-App/blob/main/Atlas_Engine_0_9_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bneQ_KxVsPc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "a29a66c9-3625-4dcf-f193-2233b8802400"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'RL_Portfolio_Trainer_v7_0'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1961383428.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpypfopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhierarchical_portfolio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHRPOpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0menum\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mRL_Portfolio_Trainer_v7_0\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_rl_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuppress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'RL_Portfolio_Trainer_v7_0'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# ======================= AI Portfolio Engine v9.2 (Dynamic Sleeves + GPR) ======================\n",
        "# Full, runnable, single-file script (Colab/local).\n",
        "# Major features:\n",
        "#   • Dynamic sleeve architecture: STOCKS, CRYPTO, LOTTERY — targets discovered each run (no fixed 70/25/5).\n",
        "#   • Anchored Gaussian Process Regression (GPR) short-horizon signal blended with ML views.\n",
        "#   • Separate stock-lottery and crypto-lottery; lottery sleeve split by best views.\n",
        "#   • Within-sleeve optimizers (BL/HRP) + ML views + RL nudges per sleeve.\n",
        "#   • Min-weight threshold to kill micro-position noise.\n",
        "#   • Optional execution suggestions: limit buys (basis-point offset) and protective stop for lottery sleeve.\n",
        "#   • Confirm-to-trade flow with cadence lock, Monte Carlo coaching, Roth integer-only + fractional taxable tickets.\n",
        "#\n",
        "# Usage:\n",
        "#   - Paste into a Colab cell and run, or save as .py and %run.\n",
        "#   - Optional: run RL trainer first to produce /content/rl_checkpoints/agent_weights.json\n",
        "#   - In a new cell: from AI_Portfolio_Engine_v9_0 import main; results = main(cadence=\"weekly\")\n",
        "#\n",
        "# Notes:\n",
        "#   - Income fields are not required; decisions are based on DCA inputs and current snapshot.\n",
        "#   - E*TRADE/broker adapters can replace CONFIG[\"initial\"] later.\n",
        "#\n",
        "import importlib, subprocess, sys, os, json, warnings\n",
        "from typing import Dict, List\n",
        "def ensure(pkg, import_name=None):\n",
        "    mod = import_name or pkg\n",
        "    try:\n",
        "        importlib.import_module(mod)\n",
        "    except ModuleNotFoundError:\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg], check=False)\n",
        "        importlib.invalidate_caches()\n",
        "\n",
        "# Pin stable versions\n",
        "for pip_name, imp in [\n",
        "    (\"yfinance==0.2.52\",\"yfinance\"),\n",
        "    (\"pandas==2.2.2\",\"pandas\"),\n",
        "    (\"numpy==1.26.4\",\"numpy\"),\n",
        "    (\"scikit-learn==1.5.1\",\"sklearn\"),\n",
        "    (\"PyPortfolioOpt==1.5.5\",\"pypfopt\"),\n",
        "    (\"matplotlib==3.9.0\",\"matplotlib\"),\n",
        "]:\n",
        "    ensure(pip_name, imp)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
        "from pypfopt import risk_models, black_litterman\n",
        "from pypfopt.hierarchical_portfolio import HRPOpt\n",
        "from enum import Enum\n",
        "from RL_Portfolio_Trainer_v7_0 import train_rl_agent\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# ---------------------------- Paths & Run Folder ----------------------------\n",
        "SAVE_DIR = \"/content/rl_checkpoints\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "RUN_ID  = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "RUN_DIR = f\"/content/run_{RUN_ID}\"\n",
        "os.makedirs(RUN_DIR, exist_ok=True)\n",
        "print(f\"[Logger] Run folder → {RUN_DIR}\")\n",
        "\n",
        "# ---------------------------- Config ----------------------------\n",
        "CONFIG = {\n",
        "    \"switches\": {\n",
        "        \"use_yfinance\": True,\n",
        "        \"use_selector_engine\": True,\n",
        "        \"use_ml_models\": True,\n",
        "        \"use_optimizer\": \"AUTO\",   # \"AUTO\" | \"BL\" | \"HRP\" | \"OFF\"\n",
        "        \"use_monte_carlo\": True,\n",
        "        \"use_rl_hook\": True,\n",
        "        \"export_trade_csv\": True,\n",
        "        \"use_balance_sync\": False\n",
        "    },\n",
        "\n",
        "    # Sleeve discovery (no fixed targets). Bounds keep sanity.\n",
        "    \"sleeves\": {\n",
        "        \"bounds\":  {\"stocks\": (0.40, 0.90), \"crypto\": (0.05, 0.40), \"lottery\": (0.00, 0.10)},\n",
        "        \"per_ticker_cap\": {\"stocks\": 0.30, \"crypto\": 0.30, \"lottery\": 1.00},\n",
        "        \"min_weight_threshold\": 0.005,     # drop <0.5%\n",
        "        \"softmax_temp\": 2.0                # higher temp = more even sleeves\n",
        "    },\n",
        "\n",
        "    # Universes (Core pistons + majors; selector can draft alternates)\n",
        "    \"stock_universe\": [\n",
        "      \"QQQM\",\"VTI\",\"AVUV\",\"AVDV\",\"SCHD\",\"O\",\"JEPI\",\"VGT\",\"DGRO\",\"VIG\",\"DIVO\",\"JEPQ\",\"TLT\",\"BIL\",\n",
        "      \"NVDA\",\"AAPL\",\"MSFT\",\"TSLA\",\"AMZN\",\"TQQQ\",\"SOXL\",\"QYLD\",\"XYLD\"],\n",
        "      \"crypto_universe\": [\n",
        "      \"BTC-USD\",\"ETH-USD\",\"SOL-USD\",\"LINK-USD\",\"ADA-USD\",\"DOT-USD\",\"AVAX-USD\",\"UNI-USD\",\"AAVE-USD\"],\n",
        "      \"stock_lottery_tickers\": [\"ARKK\",\"TQQQ\",\"SOXL\"],\n",
        "      \"crypto_lottery_tickers\": [\"DOGE-USD\",\"PTB-USD\"],\n",
        "\n",
        "\n",
        "    # Buckets\n",
        "    \"asset_classes\": {\n",
        "        \"QQQM\":\"growth\",\"VTI\":\"growth\",\"AVUV\":\"growth\",\"AVDV\":\"growth\",\"VGT\":\"growth\",\n",
        "        \"SCHD\":\"income\",\"O\":\"income\",\"JEPI\":\"income\",\"DGRO\":\"income\",\"VIG\":\"income\",\"DIVO\":\"income\",\"JEPQ\":\"income\",\"TLT\":\"income\",\"BIL\":\"income\",\n",
        "        \"ARKK\":\"growth\",\n",
        "        \"BTC-USD\":\"growth\",\"ETH-USD\":\"growth\",\"SOL-USD\":\"growth\",\"LINK-USD\":\"growth\",\"DOGE-USD\":\"growth\"\n",
        "    },\n",
        "\n",
        "    \"market_proxy\": [\"VTI\"],\n",
        "\n",
        "    # Execution hints\n",
        "    \"execution\": {\n",
        "        \"use_limit_buys\": True,          # suggest limit buys with offset (not mandatory)\n",
        "        \"limit_offset_bps\": 15,           # 15 bps below last price → limit = price * (1 - 0.0015)\n",
        "        \"use_protective_stop_lottery\": True,\n",
        "        \"stop_loss_pct_lottery\": 0.15     # 15% stop only for lottery sleeve tickers\n",
        "    },\n",
        "\n",
        "    # Accounts & DCA snapshot\n",
        "    \"initial\": {\n",
        "        \"taxable_total_value\": 5200.0,\n",
        "        \"roth_total_value\":    3500.0,\n",
        "        \"taxable_cash\": 0.0,\n",
        "        \"roth_cash\":    0.0,\n",
        "        \"taxable_positions\": {\"VTI\": 1, \"SCHD\": 1},\n",
        "        \"roth_positions\":    {\"QQQM\": 1, \"AVUV\": 1, \"AVDV\": 1}\n",
        "    },\n",
        "    \"dca\": {\"assume_today\": True, \"amount_taxable\": 260.0, \"amount_roth\": 140.0},\n",
        "\n",
        "    # Tax\n",
        "    \"tax_rates\": {\"qualified_div\": 0.15, \"ordinary_income\": 0.24},\n",
        "    \"asset_tax_types\": {\"O\":\"ordinary\",\"JEPI\":\"ordinary\",\"JEPQ\":\"ordinary\",\"XYLD\":\"ordinary\",\"TLT\":\"ordinary\"},\n",
        "\n",
        "    # Optimizer knobs\n",
        "    \"optimizer_bl_tau\": 0.05,\n",
        "    \"optimizer_view_edge_scale\": 0.60,\n",
        "\n",
        "    # Monte Carlo\n",
        "    \"goal_amount\": 1_000_000,\n",
        "    \"goal_end_date\": \"2035-12-31\",\n",
        "    \"monte_carlo_sims\": 8000,\n",
        "\n",
        "    # RL\n",
        "    \"rl_policy_path\": os.path.join(SAVE_DIR, \"agent_weights.json\"),\n",
        "    \"weights_history_path\": os.path.join(SAVE_DIR, \"last_weights.json\"),\n",
        "\n",
        "    # Data\n",
        "    \"data_start_date\": \"2015-01-01\",\n",
        "\n",
        "    \"macro_policy\": {\n",
        "      \"stance\": \"neutral\",   # \"easing\", \"tightening\", or \"neutral\"\n",
        "      \"market\": 0.0,         # optional, sentiment-style tilt (-1.0 to +1.0)\n",
        "      \"vol\": 0.0,            # optional, perceived volatility signal (-1.0 calm, +1.0 stress)\n",
        "      \"policy\": 0.0          # optional, direct policy stance (-1.0 hawkish, +1.0 dovish)\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "with open(os.path.join(RUN_DIR, \"config_snapshot.json\"), \"w\") as f:\n",
        "    json.dump(CONFIG, f, indent=2, default=str)\n",
        "\n",
        "# ---------------------------- Utilities ----------------------------\n",
        "_INFO_CACHE: Dict[str, dict] = {}\n",
        "\n",
        "def classify_bucket(ticker: str) -> str:\n",
        "    return CONFIG[\"asset_classes\"].get(ticker.upper(), \"growth\")\n",
        "\n",
        "def normalize_weights(w: Dict[str, float]) -> Dict[str, float]:\n",
        "    s = sum(max(v,0.0) for v in w.values()) or 1.0\n",
        "    return {k: max(0.0,float(v))/s for k,v in w.items()}\n",
        "\n",
        "def min_weight_prune(weights: Dict[str,float], threshold: float) -> Dict[str,float]:\n",
        "    pruned = {t: (w if w >= threshold else 0.0) for t,w in weights.items()}\n",
        "    return normalize_weights(pruned)\n",
        "\n",
        "def clip_cap(weights: Dict[str,float], cap: float) -> Dict[str,float]:\n",
        "    if cap is None or cap >= 0.999: return normalize_weights(weights)\n",
        "    w2 = {k: min(v, cap) for k,v in weights.items()}\n",
        "    return normalize_weights(w2)\n",
        "\n",
        "def fetch_prices(tickers: List[str], start: str) -> pd.DataFrame:\n",
        "    if CONFIG[\"switches\"][\"use_yfinance\"]:\n",
        "        df_full = yf.download(tickers, start=start, auto_adjust=True, progress=False,\n",
        "                              group_by=\"ticker\", threads=True)\n",
        "        closers = []\n",
        "        for t in tickers:\n",
        "            try:\n",
        "                if isinstance(df_full.columns, pd.MultiIndex):\n",
        "                    s = df_full[t][\"Close\"].rename(t)\n",
        "                else:\n",
        "                    s = df_full[\"Close\"].rename(t)\n",
        "                if not s.empty: closers.append(s)\n",
        "            except Exception:\n",
        "                warnings.warn(f\"Skipping {t}\")\n",
        "        if not closers:\n",
        "            return pd.DataFrame()\n",
        "        return pd.concat(closers, axis=1).ffill().dropna(how=\"all\")\n",
        "    # synthetic fallback\n",
        "    idx = pd.bdate_range(start=start, end=pd.Timestamp.today())\n",
        "    df = pd.DataFrame(index=idx)\n",
        "    rng = np.random.default_rng(42)\n",
        "    for t in tickers:\n",
        "        mu, sigma = (0.06, 0.12) if classify_bucket(t) == \"income\" else (0.07, 0.18)\n",
        "        daily_mu = mu/252; daily_sd = sigma/np.sqrt(252)\n",
        "        r = rng.normal(daily_mu, daily_sd, len(idx))\n",
        "        df[t] = 100 * np.cumprod(1 + r)\n",
        "    return df\n",
        "\n",
        "def _get_etf_info(t) -> dict:\n",
        "    if t in _INFO_CACHE: return _INFO_CACHE[t]\n",
        "    try: info = yf.Ticker(t).info\n",
        "    except Exception: info = {}\n",
        "    _INFO_CACHE[t] = info or {}\n",
        "    return _INFO_CACHE[t]\n",
        "\n",
        "def _avg_dollar_vol_3m(t) -> float:\n",
        "    try:\n",
        "        h = yf.Ticker(t).history(period=\"3mo\", interval=\"1d\", auto_adjust=False)\n",
        "        if h.empty: return np.nan\n",
        "        dv = (h[\"Close\"] * h[\"Volume\"]).dropna()\n",
        "        return float(dv.mean()) if not dv.empty else np.nan\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "# ---------------------------- GPR (Anchored) ----------------------------\n",
        "def anchored_gpr_signal(series: pd.Series, forecast_len=10, smooth=40, sigma=0.15) -> float:\n",
        "    s = series.dropna().values\n",
        "    if s.shape[0] < smooth: return 0.0\n",
        "    X = np.arange(len(s)).reshape(-1, 1)\n",
        "    y = np.log(s)\n",
        "    kernel = C(1.0, (1e-3, 1e3)) * RBF(length_scale=smooth, length_scale_bounds=(1, 1e3))\n",
        "    gpr = GaussianProcessRegressor(kernel=kernel, alpha=sigma**2, normalize_y=True)\n",
        "    gpr.fit(X, y)\n",
        "    Xf = np.arange(len(s), len(s)+forecast_len).reshape(-1,1)\n",
        "    y_pred, y_std = gpr.predict(Xf, return_std=True)\n",
        "    slope = y_pred[-1] - y_pred[0]\n",
        "    confidence = 1.0 - np.clip(np.mean(y_std), 0, 1)\n",
        "    return float(np.tanh(slope)) * confidence  # [-1,1]\n",
        "\n",
        "# ---------------------------- ML Views ----------------------------\n",
        "def make_features(prices: pd.DataFrame, market_series: pd.Series):\n",
        "    feats = {}\n",
        "    for t in prices.columns:\n",
        "        s = prices[t].dropna()\n",
        "        if s.shape[0] < 252: continue\n",
        "        df = pd.DataFrame(index=s.index)\n",
        "        df[\"ret_21\"]      = s.pct_change(21)\n",
        "        df[\"ret_63\"]      = s.pct_change(63)\n",
        "        df[\"vol_21\"]      = s.pct_change().rolling(21).std()\n",
        "        df[\"ma_200_dist\"] = s/s.rolling(200).mean() - 1\n",
        "        m = market_series.reindex(df.index).ffill()\n",
        "        df[\"mkt_ret_21\"]  = m.pct_change(21)\n",
        "        df[\"target\"]      = (s.shift(-21)/s - 1 > 0).astype(int)\n",
        "        feats[t] = df.dropna()\n",
        "    return feats\n",
        "\n",
        "def train_models(features: Dict[str, pd.DataFrame]) -> Dict[str, tuple]:\n",
        "    models = {}\n",
        "    for t, df in features.items():\n",
        "        X, y = df.drop(columns=[\"target\"]), df[\"target\"]\n",
        "        if len(y.unique()) < 2 or len(y) < 200: continue\n",
        "        rf = CalibratedClassifierCV(RandomForestClassifier(n_estimators=300, random_state=42), cv=3)\n",
        "        lr = CalibratedClassifierCV(LogisticRegression(max_iter=300), cv=3)\n",
        "        rf.fit(X, y); lr.fit(X, y)\n",
        "        models[t] = (rf, lr)\n",
        "    return models\n",
        "\n",
        "def get_model_views(models: Dict[str, tuple], features: Dict[str, pd.DataFrame]) -> Dict[str, float]:\n",
        "    views = {}\n",
        "    for t, mdl in models.items():\n",
        "        rf, lr = mdl\n",
        "        Xtail = features[t].drop(columns=[\"target\"]).iloc[-1:].values\n",
        "        if Xtail.shape[0]:\n",
        "            p_rf = rf.predict_proba(Xtail)[0, 1]\n",
        "            p_lr = lr.predict_proba(Xtail)[0, 1]\n",
        "            views[t] = float(0.6*p_rf + 0.4*p_lr)  # [0,1]\n",
        "    return views\n",
        "\n",
        "def blend_views_with_gpr(prices: pd.DataFrame, views: Dict[str,float], gpr_weight=0.35) -> Dict[str,float]:\n",
        "    out = {}\n",
        "    for t in prices.columns:\n",
        "        v = views.get(t, 0.5)\n",
        "        g = (anchored_gpr_signal(prices[t]) + 1)/2  # map [-1,1] -> [0,1]\n",
        "        out[t] = float((1-gpr_weight)*v + gpr_weight*g)\n",
        "    return out\n",
        "\n",
        "# ---------------------------- Candidate Screening ----------------------------\n",
        "def screen_candidates(candidates: List[str], prices: pd.DataFrame) -> List[str]:\n",
        "    screened = []\n",
        "    for t in candidates:\n",
        "        if t not in prices.columns or prices[t].dropna().shape[0] < 252*3: continue\n",
        "        info = _get_etf_info(t) if CONFIG[\"switches\"][\"use_yfinance\"] else {}\n",
        "        expense = info.get(\"expenseRatio\") or info.get(\"annualReportExpenseRatio\") or 0.003\n",
        "        aum     = info.get(\"totalAssets\") or info.get(\"totalAssetsRaw\") or 2_000_000_000\n",
        "        adv     = _avg_dollar_vol_3m(t) if CONFIG[\"switches\"][\"use_yfinance\"] else 20_000_000\n",
        "        if expense <= 0.0035 and aum >= 1_000_000_000 and (np.isnan(adv) or adv >= 10_000_000):\n",
        "            screened.append(t)\n",
        "    return screened\n",
        "\n",
        "# ---------------------------- Optimizers ----------------------------\n",
        "def _bl_weights(universe, prices, views_prob=None, tau=0.05, view_scale=0.60):\n",
        "    rets = prices[universe].pct_change().dropna()\n",
        "    if rets.empty: return {t: 1/len(universe) for t in universe}\n",
        "    S = risk_models.sample_cov(rets, frequency=252)\n",
        "    pi = rets.mean() * 252\n",
        "    Q = {}\n",
        "    if views_prob:\n",
        "        for t, p in views_prob.items():\n",
        "            if t in universe:\n",
        "                edge = (p - 0.5) * 2.0  # [-1,1]\n",
        "                Q[t] = float(pi.get(t, 0)) + view_scale * edge * abs(float(pi.get(t, 0)) + 1e-3)\n",
        "    if Q:\n",
        "        P = pd.DataFrame(0.0, index=range(len(Q)), columns=universe)\n",
        "        qv = []\n",
        "        for i, (t, v) in enumerate(Q.items()):\n",
        "            P.loc[i, t] = 1.0; qv.append(v)\n",
        "        bl = black_litterman.BlackLittermanModel(S, pi=pi, P=P.values, Q=np.array(qv), tau=tau)\n",
        "        w = pd.Series(bl.bl_weights(), dtype=float).reindex(universe).fillna(0)\n",
        "        w = w.clip(lower=0).to_dict()\n",
        "        s = sum(w.values()) or 1.0\n",
        "        return {k: v/s for k, v in w.items()}\n",
        "    hrp = HRPOpt(rets)\n",
        "    return hrp.optimize()\n",
        "\n",
        "def _hrp_weights(universe, prices):\n",
        "    rets = prices[universe].pct_change().dropna()\n",
        "    if rets.empty: return {t: 1/len(universe) for t in universe}\n",
        "    hrp = HRPOpt(rets); return hrp.optimize()\n",
        "\n",
        "def get_optimizer_weights(mode, universe, prices, views_prob):\n",
        "    mode = (mode or \"AUTO\").upper()\n",
        "    if mode == \"BL\":\n",
        "        return _bl_weights(universe, prices, views_prob, tau=CONFIG[\"optimizer_bl_tau\"],\n",
        "                           view_scale=CONFIG[\"optimizer_view_edge_scale\"])\n",
        "    if mode == \"HRP\":\n",
        "        return _hrp_weights(universe, prices)\n",
        "    if mode == \"OFF\":\n",
        "        return {t: 1/len(universe) for t in universe}\n",
        "    try:\n",
        "        w = _bl_weights(universe, prices, views_prob, tau=CONFIG[\"optimizer_bl_tau\"],\n",
        "                        view_scale=CONFIG[\"optimizer_view_edge_scale\"])\n",
        "        if sum(w.values()) > 0: return w\n",
        "    except Exception:\n",
        "        pass\n",
        "    return _hrp_weights(universe, prices)\n",
        "\n",
        "# ---------------------------- RL Nudges ----------------------------\n",
        "def apply_rl_nudges(weights: dict, path=CONFIG[\"rl_policy_path\"], blend=0.15):\n",
        "    try:\n",
        "        nudges = json.load(open(path,\"r\"))\n",
        "    except Exception:\n",
        "        return weights\n",
        "    out = {}\n",
        "    for t,w in weights.items():\n",
        "        delta = float(nudges.get(t, 0.0))\n",
        "        out[t] = max(0.0, w * (1.0 + blend * delta))\n",
        "    return normalize_weights(out)\n",
        "\n",
        "# ---------------------------- Regime & Sleeve Targets (Dynamic) ----------------------------\n",
        "def get_regime(prices: pd.DataFrame, proxy: str):\n",
        "    s = prices[proxy].dropna()\n",
        "    if s.empty or len(s) < 200:\n",
        "        return {\"name\":\"sideways\",\"confidence\":0.33}\n",
        "    ma50  = s.rolling(50).mean(); ma200 = s.rolling(200).mean()\n",
        "    spread = float((ma50.iloc[-1] - ma200.iloc[-1]) / (ma200.iloc[-1] + 1e-9))\n",
        "    vol = float(s.pct_change().rolling(21).std().iloc[-1])\n",
        "    if spread > 0.01:\n",
        "        name = \"bull\"; conf = np.clip(0.5 + spread - 0.5*vol, 0.1, 0.95)\n",
        "    elif spread < -0.01:\n",
        "        name = \"bear\"; conf = np.clip(0.5 + (-spread) - 0.5*vol, 0.1, 0.95)\n",
        "    else:\n",
        "        name = \"sideways\"; conf = 0.33\n",
        "    return {\"name\":name, \"confidence\": float(conf)}\n",
        "\n",
        "def softmax(x):\n",
        "    x = np.array(x, dtype=float)\n",
        "    x = x - np.max(x)\n",
        "    e = np.exp(x)\n",
        "    return (e / np.sum(e)).tolist()\n",
        "\n",
        "def compute_dynamic_sleeve_targets(prices: pd.DataFrame,\n",
        "                                   views_blend: Dict[str,float],\n",
        "                                   regime: dict) -> Dict[str,float]:\n",
        "    sleeves = [\"stocks\",\"crypto\",\"lottery\"]\n",
        "    bounds  = CONFIG[\"sleeves\"][\"bounds\"]\n",
        "    temp    = CONFIG[\"sleeves\"][\"softmax_temp\"]\n",
        "\n",
        "    stock_tickers  = [t for t in CONFIG[\"stock_universe\"]  if t in prices.columns]\n",
        "    crypto_tickers = [t for t in CONFIG[\"crypto_universe\"] if t in prices.columns]\n",
        "    lot_tickers    = [t for t in (CONFIG[\"stock_lottery_tickers\"] + CONFIG[\"crypto_lottery_tickers\"]) if t in prices.columns]\n",
        "\n",
        "    def sleeve_score(tickers):\n",
        "        if not tickers: return 0.0\n",
        "        v = np.mean([views_blend.get(t,0.5) for t in tickers])\n",
        "        # momentum boost\n",
        "        mom = 0.0\n",
        "        try:\n",
        "            r = prices[tickers].pct_change(21).iloc[-1].dropna()\n",
        "            mom = float(np.tanh(r.mean()*5))\n",
        "        except Exception:\n",
        "            pass\n",
        "        return float(0.7*v + 0.3*(mom+0.5))\n",
        "\n",
        "    scores = [\n",
        "        sleeve_score(stock_tickers),\n",
        "        sleeve_score(crypto_tickers),\n",
        "        sleeve_score(lot_tickers) * 0.8,\n",
        "    ]\n",
        "\n",
        "    # Regime nudges\n",
        "    if regime[\"name\"]==\"bull\":\n",
        "        scores[0] += 0.05; scores[1] += 0.03\n",
        "    elif regime[\"name\"]==\"bear\":\n",
        "        scores[0] -= 0.05; scores[1] -= 0.03\n",
        "\n",
        "    # Macro policy nudges\n",
        "    macro = CONFIG.get(\"macro_policy\", {}).get(\"stance\", None)\n",
        "    if macro == \"easing\":\n",
        "        scores[0] += 0.03   # tilt stocks\n",
        "        scores[1] += 0.02   # tilt crypto\n",
        "    elif macro == \"tightening\":\n",
        "        scores[0] -= 0.03\n",
        "        scores[1] -= 0.02\n",
        "\n",
        "    # Softmax with temperature\n",
        "    probs = np.array(softmax(np.array(scores)/max(1e-6, temp)))\n",
        "    # Clamp to bounds and renormalize\n",
        "    targets = {\"stocks\": float(np.clip(probs[0], *bounds[\"stocks\"])),\n",
        "               \"crypto\": float(np.clip(probs[1], *bounds[\"crypto\"])),\n",
        "               \"lottery\": float(np.clip(probs[2], *bounds[\"lottery\"]))}\n",
        "    s = sum(targets.values())\n",
        "    for k in targets: targets[k] /= s\n",
        "    return targets\n",
        "\n",
        "\n",
        "# ---------------------------- Sleeve Optimizations ----------------------------\n",
        "def sleeve_optimize(universe: List[str], prices: pd.DataFrame, views: Dict[str,float]) -> Dict[str,float]:\n",
        "    mode = CONFIG[\"switches\"][\"use_optimizer\"]\n",
        "    u = [t for t in universe if t in prices.columns]\n",
        "    if not u: return {}\n",
        "    weights = get_optimizer_weights(mode, u, prices, views)\n",
        "    # --- Diversification guardrail ---\n",
        "    if sum(weights.values()) > 0.30:  # sleeve got >30% of total portfolio\n",
        "        if len([w for w in weights.values() if w > 0]) < 2:\n",
        "            # force split between top 2 tickers\n",
        "            top2 = sorted(weights.items(), key=lambda x: x[1], reverse=True)[:2]\n",
        "            total = sum(v for _, v in top2) or 1.0\n",
        "            weights = {k: v/total for k, v in top2}\n",
        "\n",
        "    return weights\n",
        "\n",
        "def build_lottery_weights(stock_lot: List[str], crypto_lot: List[str],\n",
        "                          prices: pd.DataFrame, views: Dict[str,float]) -> Dict[str,float]:\n",
        "    candidates = [t for t in (stock_lot + crypto_lot) if t in prices.columns]\n",
        "    if not candidates: return {}\n",
        "    scored = sorted(candidates, key=lambda t: views.get(t, 0.5), reverse=True)\n",
        "    top = scored[:1]  # single-slot lottery\n",
        "    return normalize_weights({t: 1/len(top) for t in top})\n",
        "\n",
        "# ---------------------------- Monte Carlo & Coaching ----------------------------\n",
        "def run_monte_carlo(initial_value: float, months: int, monthly_dca: float,\n",
        "                    portfolio_returns: pd.Series, sims: int):\n",
        "    mu, sigma = float(portfolio_returns.mean()), float(portfolio_returns.std())\n",
        "    rng = np.random.default_rng(123)\n",
        "    sim = rng.normal(mu, sigma, (months, sims))\n",
        "    finals = np.full(sims, initial_value, dtype=float)\n",
        "    for i in range(months):\n",
        "        finals = finals * (1 + sim[i, :]) + monthly_dca\n",
        "    return finals\n",
        "\n",
        "def print_probability_gauge(prob: float):\n",
        "    bars = 34; filled = int(np.clip(prob,0,1)*bars)\n",
        "    color_icon = \"🟢\" if prob>=0.75 else (\"🟡\" if prob>=0.60 else \"🔴\")\n",
        "    print(\"\\n=== Probability Gauge ===\")\n",
        "    print(f\"[{color_icon}{'█'*filled}{'░'*(bars-filled)}] {prob:.1%}\")\n",
        "\n",
        "def goal_delta_coaching(prob: float, p50: float, months: int, goal: float):\n",
        "    status = \"ON TRACK\" if prob>=0.75 else (\"WATCH\" if prob>=0.60 else \"BEHIND\")\n",
        "    print(\"\\n=== Goal Delta Coaching ===\")\n",
        "    if status==\"BEHIND\":\n",
        "        short = max(0.0, goal - p50)\n",
        "        add_per_month = short/months if months>0 else 0.0\n",
        "        print(\"⚠️ Behind: increase DCA or accept higher risk.\")\n",
        "        print(f\"    Add ≈ ${add_per_month:,.0f}/month to reach median path to ${goal:,.0f}.\")\n",
        "    elif status==\"WATCH\":\n",
        "        print(\"⚠️ Watch: small DCA or sleeve tilt could push odds above 75%.\")\n",
        "    else:\n",
        "        print(\"✅ On track: consider nudging toward income to lock progress.\")\n",
        "\n",
        "# ---------------------------- Tax-aware mapping ----------------------------\n",
        "def get_tax_aware_mapping(global_w: Dict[str, float]) -> Dict[str, Dict[str, float]]:\n",
        "    roth_w, taxable_w = {}, {}\n",
        "    roth_prefers = {\"income\"}\n",
        "    for t,w in global_w.items():\n",
        "        if CONFIG[\"asset_tax_types\"].get(t)==\"ordinary\" or classify_bucket(t) in roth_prefers:\n",
        "            roth_w[t] = w\n",
        "        else:\n",
        "            taxable_w[t] = w\n",
        "    if not roth_w:    roth_w    = taxable_w.copy() or global_w.copy()\n",
        "    if not taxable_w: taxable_w = roth_w.copy() or global_w.copy()\n",
        "    return {\"roth\": normalize_weights(roth_w), \"taxable\": normalize_weights(taxable_w)}\n",
        "\n",
        "# ---------------------------- Ticketing (with execution hints) ----------------------------\n",
        "def build_trade_tickets(latest_prices: Dict[str, float], sleeve_w: Dict[str, Dict[str, float]], cash: Dict[str, float],\n",
        "                        lottery_names: List[str]):\n",
        "    fp   = 3\n",
        "    min_d = 25.0\n",
        "    taxable_orders, roth_orders = [], []\n",
        "    limit_on  = CONFIG[\"execution\"][\"use_limit_buys\"]\n",
        "    lim_bps   = CONFIG[\"execution\"][\"limit_offset_bps\"]/10000.0\n",
        "    use_stop  = CONFIG[\"execution\"][\"use_protective_stop_lottery\"]\n",
        "    stop_pct  = CONFIG[\"execution\"][\"stop_loss_pct_lottery\"]\n",
        "\n",
        "    def mk_order(t, shares, price):\n",
        "        order = {\"ticker\": t, \"shares\": shares, \"dollars\": round(shares*price,2)}\n",
        "        if limit_on:\n",
        "            order[\"order_type\"] = \"limit\"\n",
        "            order[\"limit_price\"] = round(price*(1.0 - lim_bps), 4)\n",
        "        else:\n",
        "            order[\"order_type\"] = \"market\"\n",
        "        if use_stop and t in lottery_names:\n",
        "            order[\"protective_stop\"] = round(price*(1.0 - stop_pct), 4)\n",
        "        return order\n",
        "\n",
        "    # Taxable = fractional\n",
        "    if cash[\"taxable\"] > min_d and sleeve_w[\"taxable\"]:\n",
        "        for t, w in sleeve_w[\"taxable\"].items():\n",
        "            p = float(latest_prices.get(t, 0))\n",
        "            if p <= 0: continue\n",
        "            dollars = cash[\"taxable\"] * w\n",
        "            if dollars >= min_d:\n",
        "                shares = round(dollars / p, fp)\n",
        "                if shares > 0:\n",
        "                    taxable_orders.append(mk_order(t, shares, p))\n",
        "\n",
        "    # Roth = integer-only greedy\n",
        "    if cash[\"roth\"] > min_d and sleeve_w[\"roth\"]:\n",
        "        budget = float(cash[\"roth\"]); target_w = sleeve_w[\"roth\"]\n",
        "        prices_now = {t: float(latest_prices.get(t, 0)) for t in target_w if float(latest_prices.get(t, 0)) > 0}\n",
        "        shares_to_buy = {t: 0 for t in prices_now}; spent = 0.0\n",
        "        for _ in range(100000):\n",
        "            under = {t: (budget*target_w.get(t,0) - shares_to_buy[t]*prices_now[t]) for t in prices_now}\n",
        "            if not under: break\n",
        "            best = max(under, key=under.get)\n",
        "            price = prices_now[best]\n",
        "            if price < min_d or spent + price > budget: break\n",
        "            shares_to_buy[best] += 1; spent += price\n",
        "        for t, n in shares_to_buy.items():\n",
        "            if n > 0:\n",
        "                roth_orders.append(mk_order(t, int(n), prices_now[t]))\n",
        "    return {\"taxable\": taxable_orders, \"roth\": roth_orders}\n",
        "\n",
        "# ---------------------------- Confirm-to-trade State Machine ----------------------------\n",
        "class State(Enum): IDLE=0; PROPOSE=1; AWAIT_CONFIRM=2; EXECUTING=3; COOLDOWN=4\n",
        "STATE = State.IDLE\n",
        "LOCK_UNTIL = None  # pd.Timestamp\n",
        "\n",
        "def propose_trades(tickets, cadence=\"weekly\"):\n",
        "    global STATE, LOCK_UNTIL\n",
        "    now = pd.Timestamp.utcnow()\n",
        "    if STATE in (State.COOLDOWN, State.AWAIT_CONFIRM) and LOCK_UNTIL is not None and now < LOCK_UNTIL:\n",
        "        print(\"⏳ Locked until\", LOCK_UNTIL); return None\n",
        "    STATE = State.PROPOSE\n",
        "    print(\"\\n🧾 Proposed trades:\", json.dumps(tickets, indent=2))\n",
        "    STATE = State.AWAIT_CONFIRM\n",
        "    days = {\"daily\":1, \"weekly\":7, \"monthly\":30}.get(cadence, 1)\n",
        "    LOCK_UNTIL = now + pd.Timedelta(days=days)\n",
        "    return {\"expires_at\": LOCK_UNTIL.isoformat()}\n",
        "\n",
        "def confirm_execute(place_order_fn, tickets):\n",
        "    global STATE\n",
        "    if STATE != State.AWAIT_CONFIRM:\n",
        "        print(\"No pending proposal.\"); return\n",
        "    STATE = State.EXECUTING\n",
        "    try:\n",
        "        place_order_fn(tickets)\n",
        "        STATE = State.COOLDOWN\n",
        "        print(\"✅ Orders placed. Cooldown in effect.\")\n",
        "    except Exception as e:\n",
        "        STATE = State.IDLE\n",
        "        print(f\"❌ Execution failed: {e}\")\n",
        "\n",
        "def cancel_proposal():\n",
        "    global STATE\n",
        "    if STATE == State.AWAIT_CONFIRM: STATE = State.IDLE\n",
        "# ================= Broker Adapters (stubs) =================\n",
        "def fetch_etrade_trade_history(account_id=None, count=100):\n",
        "    \"\"\"\n",
        "    Pull last N trades from E*TRADE API.\n",
        "    Return list of dicts with standard schema:\n",
        "    date, symbol, type, price, quantity, cost, fee, pl\n",
        "    \"\"\"\n",
        "    # TODO: wire up to real E*TRADE API\n",
        "    return [\n",
        "        {\"date\": \"2025-09-01\", \"symbol\": \"VTI\", \"type\": \"BUY\",\n",
        "         \"price\": 250.0, \"quantity\": 2, \"cost\": 500.0, \"fee\": 0.0, \"pl\": 0.0}\n",
        "    ]\n",
        "\n",
        "def fetch_kraken_trade_history(count=100):\n",
        "    \"\"\"\n",
        "    Pull last N trades from Kraken API.\n",
        "    Return list of dicts with standard schema:\n",
        "    date, pair, type, price, quantity, cost, fee, pl\n",
        "    \"\"\"\n",
        "    # TODO: wire up to real Kraken API\n",
        "    return [\n",
        "        {\"date\": \"2025-09-05\", \"pair\": \"BTC-USD\", \"type\": \"BUY\",\n",
        "         \"price\": 60000.0, \"quantity\": 0.01, \"cost\": 600.0, \"fee\": 1.0, \"pl\": 0.0}\n",
        "    ]\n",
        "\n",
        "def place_order_etrade(tickets):\n",
        "    \"\"\"\n",
        "    Place trades with E*TRADE.\n",
        "    For now, just print. Replace with API calls later.\n",
        "    \"\"\"\n",
        "    for acct, orders in tickets.items():\n",
        "        for order in orders:\n",
        "            print(f\"[E*TRADE] {acct.upper()} placing {order['order_type']} \"\n",
        "                  f\"order for {order['shares']}x {order['ticker']} \"\n",
        "                  f\"(${order.get('limit_price') or order['dollars']})\")\n",
        "\n",
        "def place_order_kraken(tickets):\n",
        "    \"\"\"\n",
        "    Place trades with Kraken.\n",
        "    For now, just print. Replace with API calls later.\n",
        "    \"\"\"\n",
        "    for acct, orders in tickets.items():\n",
        "        for order in orders:\n",
        "            print(f\"[Kraken] {acct.upper()} placing {order['order_type']} \"\n",
        "                  f\"order for {order['shares']} {order['ticker']} \"\n",
        "                  f\"(stop {order.get('protective_stop')})\")\n",
        "\n",
        "# ================= Trade History Reflection =================\n",
        "def analyze_trade_history(trades, lookback_days=90, console=True):\n",
        "    \"\"\"\n",
        "    Analyze recent trade history and return a dict for reflection.\n",
        "    Optionally print a coach-style recap if console=True.\n",
        "    \"\"\"\n",
        "    import pandas as pd, numpy as np\n",
        "    if not trades:\n",
        "        if console:\n",
        "            print(\"\\n=== Trade History Reflection ===\\nNo trades found in history.\")\n",
        "        return {\"message\": \"No trades found in history.\"}\n",
        "\n",
        "    df = pd.DataFrame(trades).copy()\n",
        "    if \"symbol\" not in df.columns and \"pair\" in df.columns:\n",
        "        df[\"symbol\"] = df[\"pair\"]\n",
        "\n",
        "    # Parse dates\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"], unit=\"s\", errors=\"coerce\") \\\n",
        "                   .fillna(pd.to_datetime(df[\"date\"], errors=\"coerce\"))\n",
        "    cutoff = pd.Timestamp.utcnow() - pd.Timedelta(days=lookback_days)\n",
        "    recent = df[df[\"date\"] >= cutoff].copy()\n",
        "    if recent.empty:\n",
        "        if console:\n",
        "            print(f\"\\n=== Trade History Reflection ===\\nNo trades in the last {lookback_days} days.\")\n",
        "        return {\"message\": f\"No trades in the last {lookback_days} days.\"}\n",
        "\n",
        "    realized_pl = float(recent[\"pl\"].sum() if \"pl\" in recent else 0.0)\n",
        "    total_fees  = float(recent[\"fee\"].sum() if \"fee\" in recent else 0.0)\n",
        "    wins = int((recent[\"pl\"] > 0).sum() if \"pl\" in recent else 0)\n",
        "    losses = int((recent[\"pl\"] < 0).sum() if \"pl\" in recent else 0)\n",
        "    total = max(1, wins + losses)\n",
        "    win_rate = wins / total\n",
        "\n",
        "    # Average hold\n",
        "    avg_hold_days = None\n",
        "    try:\n",
        "        hold_times = []\n",
        "        for sym in recent[\"symbol\"].unique():\n",
        "            sym_trades = recent[recent[\"symbol\"] == sym].sort_values(\"date\")\n",
        "            stack = []\n",
        "            for _, row in sym_trades.iterrows():\n",
        "                if row[\"type\"].upper() == \"BUY\":\n",
        "                    stack.append(row[\"date\"])\n",
        "                elif row[\"type\"].upper() == \"SELL\" and stack:\n",
        "                    buy_date = stack.pop(0)\n",
        "                    hold_times.append((row[\"date\"] - buy_date).days)\n",
        "        if hold_times:\n",
        "            avg_hold_days = float(np.mean(hold_times))\n",
        "    except Exception:\n",
        "        avg_hold_days = None\n",
        "\n",
        "    reflection = {\n",
        "        \"lookback_days\": lookback_days,\n",
        "        \"realized_pl\": realized_pl,\n",
        "        \"total_fees\": total_fees,\n",
        "        \"net_pl\": realized_pl - total_fees,\n",
        "        \"wins\": wins,\n",
        "        \"losses\": losses,\n",
        "        \"win_rate\": float(win_rate),\n",
        "        \"avg_hold_days\": avg_hold_days,\n",
        "        \"best\": None,\n",
        "        \"worst\": None,\n",
        "        \"sleeve_attribution\": None\n",
        "    }\n",
        "\n",
        "    # Best/Worst\n",
        "    if \"symbol\" in recent:\n",
        "        grp = recent.groupby(\"symbol\")[\"pl\"].sum().sort_values(ascending=False)\n",
        "        if not grp.empty:\n",
        "            reflection[\"best\"]  = {\"symbol\": grp.index[0], \"pl\": float(grp.values[0])}\n",
        "            reflection[\"worst\"] = {\"symbol\": grp.index[-1], \"pl\": float(grp.values[-1])}\n",
        "\n",
        "    # Sleeve attribution\n",
        "    try:\n",
        "        def classify_sleeve(sym: str):\n",
        "            if sym in CONFIG[\"crypto_universe\"]: return \"crypto\"\n",
        "            if sym in CONFIG[\"stock_lottery_tickers\"] or sym in CONFIG[\"crypto_lottery_tickers\"]: return \"lottery\"\n",
        "            if CONFIG[\"asset_classes\"].get(sym) == \"income\": return \"income\"\n",
        "            return \"growth\"\n",
        "        recent[\"sleeve\"] = recent[\"symbol\"].map(classify_sleeve)\n",
        "        sleeve_grp = recent.groupby(\"sleeve\")[\"pl\"].sum().to_dict()\n",
        "        reflection[\"sleeve_attribution\"] = {k: float(v) for k,v in sleeve_grp.items()}\n",
        "    except Exception:\n",
        "        reflection[\"sleeve_attribution\"] = None\n",
        "\n",
        "    # === Console Recap ===\n",
        "    if console:\n",
        "        bars = 34\n",
        "        filled = int(np.clip(win_rate,0,1)*bars)\n",
        "        color_icon = \"🟢\" if win_rate>=0.65 else (\"🟡\" if win_rate>=0.50 else \"🔴\")\n",
        "        print(\"\\n=== Trade History Reflection ===\")\n",
        "        print(f\"[{color_icon}{'█'*filled}{'░'*(bars-filled)}] {win_rate:.1%} win rate over last {lookback_days} days\")\n",
        "        print(f\"• Realized P/L: ${realized_pl:,.2f} (Net: ${realized_pl-total_fees:,.2f} after ${total_fees:,.2f} fees)\")\n",
        "        print(f\"• Trades: {total} (Wins: {wins}, Losses: {losses})\")\n",
        "        if avg_hold_days is not None:\n",
        "            print(f\"• Avg Hold: {avg_hold_days:.1f} days\")\n",
        "        if reflection[\"best\"]: print(f\"• Best: {reflection['best']['symbol']} +${reflection['best']['pl']:,.2f}\")\n",
        "        if reflection[\"worst\"]: print(f\"• Worst: {reflection['worst']['symbol']} ${reflection['worst']['pl']:,.2f}\")\n",
        "        if reflection[\"sleeve_attribution\"]:\n",
        "            print(\"• Sleeve Attribution:\")\n",
        "            for s,v in reflection[\"sleeve_attribution\"].items():\n",
        "                print(f\"   {s}: ${v:,.2f}\")\n",
        "\n",
        "    return reflection\n",
        "\n",
        "\n",
        "def retrain_agent(run_sweep=True):\n",
        "    \"\"\"\n",
        "    Kick off an RL retraining cycle and return paths to new nudges + eval summary.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        res = train_rl_agent(run_sweep_flag=run_sweep, export_nudges_flag=True)\n",
        "        return {\"status\": \"ok\", \"paths\": res}\n",
        "    except Exception as e:\n",
        "        return {\"status\": \"error\", \"error\": str(e)}\n",
        "\n",
        "# ---------------------------- Main ----------------------------\n",
        "# ================= Logging & RL Eval =================\n",
        "LOG_DB = \"/content/portfolio_log.json\"\n",
        "\n",
        "def append_run_log(entry: dict, path=LOG_DB):\n",
        "    import json, os\n",
        "    all_logs = []\n",
        "    if os.path.exists(path):\n",
        "        with open(path, \"r\") as f:\n",
        "            try: all_logs = json.load(f)\n",
        "            except: all_logs = []\n",
        "    all_logs.append(entry)\n",
        "    with open(path, \"w\") as f:\n",
        "        json.dump(all_logs, f, indent=2, default=str)\n",
        "\n",
        "def load_rl_eval_summary(path=os.path.join(SAVE_DIR, \"evaluation_summary.json\")):\n",
        "    import json\n",
        "    try:\n",
        "        with open(path, \"r\") as f:\n",
        "            return json.load(f)\n",
        "    except Exception:\n",
        "        return {\"message\": \"No RL eval summary found.\"}\n",
        "def last_business_day(d):\n",
        "    d = pd.to_datetime(d); return d - pd.offsets.BDay(0)\n",
        "\n",
        "def main(cadence=\"weekly\"):\n",
        "    sleeves_cfg = CONFIG[\"sleeves\"]\n",
        "    # Assemble universes\n",
        "    stock_u = list(dict.fromkeys(CONFIG[\"stock_universe\"] + CONFIG[\"stock_lottery_tickers\"]))\n",
        "    crypto_u = list(dict.fromkeys(CONFIG[\"crypto_universe\"] + CONFIG[\"crypto_lottery_tickers\"]))\n",
        "    base_universe = sorted(set(stock_u + crypto_u))\n",
        "\n",
        "    prices = fetch_prices(base_universe, CONFIG[\"data_start_date\"]).dropna(how=\"all\")\n",
        "    if prices.empty:\n",
        "        raise RuntimeError(\"Price fetch returned empty. Check tickers or network.\")\n",
        "    latest_px = {t: float(prices[t].iloc[-1]) for t in prices.columns}\n",
        "\n",
        "    # Selector engine (stocks only) – drafts alternates by cost/liquidity\n",
        "    if CONFIG[\"switches\"][\"use_selector_engine\"] and CONFIG[\"switches\"][\"use_yfinance\"]:\n",
        "        filtered = screen_candidates(CONFIG[\"stock_universe\"], prices)\n",
        "        if filtered:\n",
        "            CONFIG[\"stock_universe\"] = sorted(set(filtered) | set([t for t in CONFIG[\"stock_universe\"] if t in filtered]))\n",
        "\n",
        "    # ML views + GPR blend\n",
        "    views = {}\n",
        "    if CONFIG[\"switches\"][\"use_ml_models\"]:\n",
        "        feats = make_features(prices, prices[CONFIG[\"market_proxy\"][0]])\n",
        "        models = train_models(feats)\n",
        "        views = get_model_views(models, feats)\n",
        "    blended_views = blend_views_with_gpr(prices, views, gpr_weight=0.35)\n",
        "\n",
        "    # Regime + dynamic sleeve targets\n",
        "    regime = get_regime(prices, CONFIG[\"market_proxy\"][0])\n",
        "    sleeve_targets = compute_dynamic_sleeve_targets(prices, blended_views, regime)\n",
        "\n",
        "    # Optimize within sleeves (exclude lottery tickers)\n",
        "    stock_core  = [t for t in CONFIG[\"stock_universe\"]  if t not in CONFIG[\"stock_lottery_tickers\"]]\n",
        "    crypto_core = [t for t in CONFIG[\"crypto_universe\"] if t not in CONFIG[\"crypto_lottery_tickers\"]]\n",
        "\n",
        "    w_stocks = sleeve_optimize(stock_core, prices, blended_views)\n",
        "    w_crypto = sleeve_optimize(crypto_core, prices, blended_views)\n",
        "\n",
        "    # RL nudges per sleeve\n",
        "    if CONFIG[\"switches\"][\"use_rl_hook\"]:\n",
        "        w_stocks = apply_rl_nudges(w_stocks, path=CONFIG[\"rl_policy_path\"], blend=0.15)\n",
        "        w_crypto = apply_rl_nudges(w_crypto, path=CONFIG[\"rl_policy_path\"], blend=0.15)\n",
        "\n",
        "    # Caps & prune\n",
        "    w_stocks = clip_cap(w_stocks, sleeves_cfg[\"per_ticker_cap\"][\"stocks\"])\n",
        "    w_crypto = clip_cap(w_crypto, sleeves_cfg[\"per_ticker_cap\"][\"crypto\"])\n",
        "    w_stocks = min_weight_prune(w_stocks, sleeves_cfg[\"min_weight_threshold\"])\n",
        "    w_crypto = min_weight_prune(w_crypto, sleeves_cfg[\"min_weight_threshold\"])\n",
        "\n",
        "    # Lottery per sleeve\n",
        "    w_lottery = build_lottery_weights(CONFIG[\"stock_lottery_tickers\"], CONFIG[\"crypto_lottery_tickers\"], prices, blended_views)\n",
        "\n",
        "    # Compose final portfolio from sleeves\n",
        "    portfolio = {}\n",
        "    for t,w in w_stocks.items():\n",
        "        portfolio[t] = portfolio.get(t,0.0) + sleeve_targets[\"stocks\"] * w\n",
        "    for t,w in w_crypto.items():\n",
        "        portfolio[t] = portfolio.get(t,0.0) + sleeve_targets[\"crypto\"] * w\n",
        "    for t,w in w_lottery.items():\n",
        "        portfolio[t] = portfolio.get(t,0.0) + sleeve_targets[\"lottery\"] * w\n",
        "    portfolio = normalize_weights(portfolio)\n",
        "\n",
        "    # Map to accounts\n",
        "    sleeve_w = get_tax_aware_mapping(portfolio)\n",
        "\n",
        "    # Tickets with execution hints\n",
        "    cash = {\"taxable\": CONFIG[\"dca\"][\"amount_taxable\"], \"roth\": CONFIG[\"dca\"][\"amount_roth\"]}\n",
        "    lottery_names = list(w_lottery.keys())\n",
        "    tickets = build_trade_tickets(latest_px, sleeve_w, cash, lottery_names)\n",
        "\n",
        "    # Monte Carlo\n",
        "    months = int((pd.to_datetime(CONFIG[\"goal_end_date\"]) - last_business_day(pd.Timestamp.today())).days/30.44)\n",
        "    initial_value = CONFIG[\"initial\"][\"taxable_total_value\"] + CONFIG[\"initial\"][\"roth_total_value\"]\n",
        "    monthly_dca = CONFIG[\"dca\"][\"amount_taxable\"] + CONFIG[\"dca\"][\"amount_roth\"]\n",
        "    cols = [t for t in portfolio if t in prices.columns]\n",
        "    port_rets = prices[cols].pct_change().dropna().dot(pd.Series(portfolio).reindex(cols).fillna(0))\n",
        "    finals = run_monte_carlo(initial_value, months, monthly_dca, port_rets, CONFIG[\"monte_carlo_sims\"]) if CONFIG[\"switches\"][\"use_monte_carlo\"] else np.array([])\n",
        "    prob = float((finals >= CONFIG[\"goal_amount\"]).mean()) if finals.size else 0.0\n",
        "    p50  = float(np.median(finals)) if finals.size else initial_value\n",
        "    print_probability_gauge(prob); goal_delta_coaching(prob, p50, months, CONFIG[\"goal_amount\"])\n",
        "\n",
        "    # Export CSV\n",
        "    if CONFIG[\"switches\"][\"export_trade_csv\"]:\n",
        "        out_path = os.path.join(RUN_DIR, \"proposed_trades.csv\")\n",
        "        rows = [(\"taxable\",o[\"ticker\"],o[\"shares\"],o[\"dollars\"],o.get(\"order_type\"),o.get(\"limit_price\"),o.get(\"protective_stop\")) for o in tickets[\"taxable\"]] + \\\n",
        "               [(\"roth\",   o[\"ticker\"],o[\"shares\"],o[\"dollars\"],o.get(\"order_type\"),o.get(\"limit_price\"),o.get(\"protective_stop\")) for o in tickets[\"roth\"]]\n",
        "        pd.DataFrame(rows, columns=[\"account\",\"ticker\",\"shares\",\"dollars\",\"order_type\",\"limit_price\",\"protective_stop\"]).to_csv(out_path, index=False)\n",
        "        print(f\"\\nSaved proposed trades → {out_path}\")\n",
        "\n",
        "    # Propose + lock\n",
        "    lock_info = propose_trades(tickets, cadence=cadence)\n",
        "    print(\"Lock Info:\", lock_info)\n",
        "\n",
        "    # --- Add reflection + RL eval + persistence ---\n",
        "    try:\n",
        "        etrade_trades = fetch_etrade_trade_history(account_id, count=100)\n",
        "    except Exception:\n",
        "        etrade_trades = []\n",
        "    try:\n",
        "        kraken_trades = fetch_kraken_trade_history(count=100)\n",
        "    except Exception:\n",
        "        kraken_trades = []\n",
        "\n",
        "    all_trades = etrade_trades + kraken_trades\n",
        "    trade_reflection = analyze_trade_history(all_trades, lookback_days=90)\n",
        "\n",
        "    results = {\n",
        "        \"sleeve_targets\": sleeve_targets,\n",
        "        \"portfolio_weights\": portfolio,\n",
        "        \"sleeve_accounts\": sleeve_w,\n",
        "        \"tickets\": tickets,\n",
        "        \"probability\": prob,\n",
        "        \"p50\": p50,\n",
        "        \"run_dir\": RUN_DIR,\n",
        "        \"trade_reflection\": trade_reflection,\n",
        "        \"rl_evaluation\": load_rl_eval_summary(),\n",
        "        \"rl_retrain_available\": True\n",
        "    }\n",
        "\n",
        "    append_run_log(results)\n",
        "    return results\n",
        "\n",
        "# ================= Resilience Wrapper =================\n",
        "def safe_run(func, *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Run engine/trainer functions safely.\n",
        "    Returns {\"status\": \"ok\", \"results\": ...} or {\"status\": \"error\", \"error\": str}.\n",
        "    Also logs errors to portfolio_log.json.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        res = func(*args, **kwargs)\n",
        "        return {\"status\": \"ok\", \"results\": res}\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        err_msg = f\"{type(e).__name__}: {e}\"\n",
        "        tb = traceback.format_exc()\n",
        "        error_payload = {\"status\": \"error\", \"error\": err_msg, \"traceback\": tb}\n",
        "        try:\n",
        "            append_run_log(error_payload)\n",
        "        except Exception:\n",
        "            pass\n",
        "        print(f\"❌ SafeRun caught error: {err_msg}\")\n",
        "        return error_payload\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = main(cadence=\"weekly\")\n",
        "    print(json.dumps(results, indent=2, default=str))"
      ]
    }
  ]
}